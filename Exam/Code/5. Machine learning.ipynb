{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a1be962-28d8-424d-a21d-025f8fb79c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve, validation_curve \n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from PIL import Image\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81e4eebe-0b5c-4010-8f18-b7a543dabe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "fp_data = Path.cwd()\n",
    "file_path = fp_data/ 'data_processed.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create X variables as description, title and other variables\n",
    "X_des = df['proc_de']\n",
    "X_tit = df['proc_ti']\n",
    "X_num = df.drop(columns = ['proc_de', 'proc_ti', 'Avg_ratings'])\n",
    "\n",
    "# Create y variable as average ratings \n",
    "y = df['Avg_ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c05a151c-62f4-453c-bb56-b2cfbce12a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into development (2/3) and test data (1/3)\n",
    "X_dev_tit, X_test_tit, y_dev, y_test = train_test_split(X_tit, y, test_size=1/3, random_state=1234)\n",
    "X_dev_des, X_test_des = train_test_split(X_des, test_size=1/3, random_state=1234)\n",
    "X_dev_num, X_test_num = train_test_split(X_num, test_size=1/3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a91dd-05fe-4232-89fe-772321a54b72",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7676366c-6eb2-464d-84f7-f40338390d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter list for all X's \n",
    "lambdas = np.logspace(-4, 4, 10)\n",
    "degrees = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1cc1c0de-8c1a-4da8-8ceb-c28a6b7e0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for processed titles and description\n",
    "pipe_words_las = make_pipeline(TfidfVectorizer(),\n",
    "    Lasso(random_state=1234))\n",
    "\n",
    "# param grid used for titles and description\n",
    "param_words_las = {'lasso__alpha': lambdas}\n",
    "   \n",
    "# Gridsearch for processed titles and description\n",
    "gs_lasso_title = GridSearchCV(pipe_words_las, param_words_las, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)\n",
    "gs_lasso_des = GridSearchCV(pipe_words_las, param_words_las, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a90bbab-d9e1-49e4-8c41-2edfb8124e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical variables\n",
    "pipe_num_las = make_pipeline(PolynomialFeatures(include_bias=True),\n",
    "    StandardScaler(),\n",
    "    Lasso(random_state=1234))\n",
    "\n",
    "# param grid used for titles and description\n",
    "param_num_las = {'polynomialfeatures__degree': degrees,\n",
    "            'lasso__alpha': lambdas}\n",
    "\n",
    "# Gridsearch for numerical variables\n",
    "gs_lasso_num = GridSearchCV(pipe_num_las, param_num_las, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f10ba0d-7e47-490a-8575-aac01207ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append result to a list\n",
    "las_result = []\n",
    "\n",
    "# Fit title words\n",
    "gs_lasso_title.fit(X_dev_tit, y_dev)\n",
    "las_result.append(gs_lasso_title)\n",
    "\n",
    "# Fit description words\n",
    "gs_lasso_des.fit(X_dev_des, y_dev)\n",
    "las_result.append(gs_lasso_des)\n",
    "\n",
    "# Fit numerical values\n",
    "gs_lasso_num.fit(X_dev_num, y_dev)\n",
    "las_result.append(gs_lasso_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4b0cb737-8897-4d0e-b6c2-5864b2133bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_models = ['Lasso_title', 'Lasso_des', 'Lasso_num']\n",
    "las_dataset = [X_dev_tit, X_dev_des, X_dev_num]\n",
    "accu_las = []\n",
    "mse_las = []\n",
    "para_las = []\n",
    "\n",
    "#prints parameters, mse and accuracy for the best model\n",
    "for i, name in enumerate(las_models):\n",
    "    para = las_result[i].best_params_ #best hyperparameters\n",
    "    para_las.append(para)\n",
    "    \n",
    "    mse_l = -las_result[i].best_score_ #best mse \n",
    "    mse_las.append(mse_l)\n",
    "    \n",
    "    y_hat = las_result[i].predict(las_dataset[i]) # Use the best model to make predictions\n",
    "    accuracy = np.mean(y_dev.round(1)==y_hat.round(1)) #accuracy of the best model\n",
    "    accu_las.append(accuracy)\n",
    "    \n",
    "    print(f'{name} Best parameter set: {para}', \n",
    "          f'Best mse: {mse_l}',\n",
    "          f'Best accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446579c-2c9c-44ab-a23a-9ea5840d2b8c",
   "metadata": {},
   "source": [
    "## Elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b2cb438-4b55-42ad-be3e-bbb0bb06202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter list for all X's \n",
    "lambdas = np.logspace(-4, 4, 10)\n",
    "degrees = [1,2,3]\n",
    "ela__l1_ratio = np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45b5d36f-bf89-498d-96e6-b252fa7ff7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for processed titles and description\n",
    "pipe_words_elas = make_pipeline(TfidfVectorizer(),\n",
    "                                ElasticNet(random_state=1234))\n",
    "\n",
    "# param grid used for titles and description\n",
    "param_words_elas = {'elasticnet__alpha': lambdas,\n",
    "                   'elasticnet__l1_ratio': ela__l1_ratio}\n",
    "   \n",
    "# Gridsearch for processed titles and description\n",
    "gs_elas_title = GridSearchCV(pipe_words_elas, param_words_elas, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)\n",
    "gs_elas_des = GridSearchCV(pipe_words_elas, param_words_elas, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f8cd2f95-2d09-4e77-a667-71974835bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical variables\n",
    "pipe_num_ela = make_pipeline(PolynomialFeatures(include_bias=True),\n",
    "    StandardScaler(),\n",
    "    ElasticNet(random_state=1234))\n",
    "\n",
    "# param grid used for titles and description\n",
    "param_num_ela = {'polynomialfeatures__degree': degrees,\n",
    "                'elasticnet__alpha': lambdas,\n",
    "                'elasticnet__l1_ratio': ela__l1_ratio}\n",
    "\n",
    "# Gridsearch for numerical variables\n",
    "gs_elas_num = GridSearchCV(pipe_num_ela, param_num_ela, scoring='neg_mean_squared_error', cv=3,  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "22f153a7-b193-42b6-9d8f-5d4a9e3097b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append result to a list\n",
    "elastic_result = []\n",
    "\n",
    "# Fit title words\n",
    "gs_elas_title.fit(X_dev_tit, y_dev)\n",
    "elastic_result.append(gs_elas_title)\n",
    "\n",
    "# Fit description words\n",
    "gs_elas_des.fit(X_dev_des, y_dev)\n",
    "elastic_result.append(gs_elas_des)\n",
    "\n",
    "# Fit numerical values\n",
    "gs_elas_num.fit(X_dev_num, y_dev)\n",
    "elastic_result.append(gs_elas_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cda093ee-b251-42c7-bbc4-cdfbc37c6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "elas_models = ['Elastic_title', 'Elastic_des', 'Elastic_num']\n",
    "elas_dataset = [X_dev_tit, X_dev_des, X_dev_num]\n",
    "accu_elas = []\n",
    "mse_elas = []\n",
    "para_elas = []\n",
    "\n",
    "#prints parameters, mse and accuracy for the best model\n",
    "for i, name in enumerate(elas_models):\n",
    "    mse_e = -elastic_result[i].best_score_\n",
    "    mse_elas.append(mse_e)\n",
    "    \n",
    "    y_hat = elastic_result[i].predict(elas_dataset[i])\n",
    "    accuracy = np.mean(y_dev.round(1)==y_hat.round(1))\n",
    "    accu_elas.append(accuracy)\n",
    "                    \n",
    "    para = elastic_result[i].best_params_\n",
    "    para_elas.append(para)\n",
    "    \n",
    "    print(f'{name} Best parameter set: {para}', \n",
    "          f'Best mse: {mse_e}',\n",
    "          f'Best accuracy: {accuracy}')                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fa64a-8384-4daa-beab-33be1e639680",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8c9f17df-5430-46d9-8360-ef7e8900ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter list for all X's \n",
    "degrees = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "98298b7f-eb03-488f-a634-4c0ee8d99907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold on OLS\n",
    "## Titel\n",
    "\n",
    "kfold = KFold(n_splits=3)\n",
    "folds_tit = list(kfold.split(X_dev_tit, y_dev))\n",
    "mseTit = []\n",
    "accTit = []\n",
    "\n",
    "for train_idx, val_idx in folds_tit:\n",
    "    pipe_words_ols = make_pipeline(TfidfVectorizer(),\n",
    "                                LinearRegression())\n",
    "    X_train_tit, y_train = X_dev_tit.iloc[train_idx], y_dev[train_idx]\n",
    "    X_val_tit, y_val = X_dev_tit.iloc[val_idx], y_dev[val_idx]\n",
    "    pipe_words_ols.fit(X_train_tit, y_train)\n",
    "    \n",
    "    mseTit.append(mse(pipe_words_ols.predict(X_val_tit), y_val))\n",
    "    accTit.append(np.mean(pipe_words_ols.predict(X_val_tit).round(1)==y_val.round(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79706dde-037b-41db-b92e-c98c1b08f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "folds_des = list(kfold.split(X_dev_des, y_dev))\n",
    "mseDes = []\n",
    "accDes = []\n",
    "\n",
    "for train_idx, val_idx in folds_des:\n",
    "    pipe_words_ols = make_pipeline(TfidfVectorizer(),\n",
    "                                LinearRegression())\n",
    "    X_train_des, y_train = X_dev_des.iloc[train_idx], y_dev[train_idx]\n",
    "    X_val_des, y_val = X_dev_des.iloc[val_idx], y_dev[val_idx]\n",
    "    pipe_words_ols.fit(X_train_des, y_train)\n",
    "    \n",
    "    mseDes.append(mse(pipe_words_ols.predict(X_val_des), y_val))\n",
    "    accDes.append(np.mean(pipe_words_ols.predict(X_val_des).round(1)==y_val.round(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a088dfc1-9bc2-46c1-9e96-526c2bdd72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical variables\n",
    "pipe_num_ols = make_pipeline(PolynomialFeatures(include_bias=True),\n",
    "    StandardScaler(),\n",
    "    LinearRegression())\n",
    "\n",
    "# param grid used for titles and description\n",
    "param_num_ols = {'polynomialfeatures__degree': degrees}\n",
    "\n",
    "# Gridsearch for numerical variables\n",
    "gs_ols_num = GridSearchCV(pipe_num_ols, param_num_ols, scoring='neg_mean_squared_error', cv=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "68be825e-f714-423a-8858-d6dace73e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit numerical values\n",
    "gs_ols_num.fit(X_dev_num, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9a8f11e8-84f9-4d2c-8729-46250abcdca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_ols = []\n",
    "mse_ols = []\n",
    "\n",
    "# Title: \n",
    "MSE_tit = np.mean(mseTit)\n",
    "accuracy_tit = np.mean(accTit) \n",
    "\n",
    "# Description\n",
    "MSE_des = np.mean(mseDes)\n",
    "accuracy_des =  np.mean(accDes) \n",
    "\n",
    "#Numerical variables\n",
    "\n",
    "y_hat_num = gs_ols_num.predict(X_dev_num)\n",
    "MSE_num = -gs_ols_num.best_score_\n",
    "accuracy_num = np.mean(y_dev.round(1)==y_hat_num.round(1))\n",
    "\n",
    "#Append MSE and accuracy to list\n",
    "mse_ols.append(MSE_tit)\n",
    "mse_ols.append(MSE_des)\n",
    "mse_ols.append(MSE_num)\n",
    "\n",
    "accu_ols.append(accuracy_tit)\n",
    "accu_ols.append(accuracy_des)\n",
    "accu_ols.append(accuracy_num)\n",
    "\n",
    "para_ols = gs_ols_num.best_params_ #dictionary\n",
    "\n",
    "ols_models = ['OLS_title', 'OLS_des', 'OLS_num']\n",
    "\n",
    "#prints mse and accuracy for the best model and best parameters for numerical variables\n",
    "for i, name in enumerate(ols_models):\n",
    "    print(f'{name}Best mse: {mse_ols[i]}',\n",
    "          f'Best accuracy: {accu_ols[i]}')\n",
    "    \n",
    "print(f'{ols_models[2]} Best parameter set: {gs_ols_num.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2864a8f-dea3-4b35-85ce-d2cfc7a3c215",
   "metadata": {},
   "source": [
    "## Lasso - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "80926d8a-d69e-4990-b05c-eb5d28ce506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title pipeline\n",
    "pipe_tit_las_best = make_pipeline(TfidfVectorizer(),\n",
    "    Lasso(alpha = para_las[0]['lasso__alpha'], random_state=1234))\n",
    "\n",
    "#Description pipeline\n",
    "pipe_des_las_best = make_pipeline(TfidfVectorizer(),\n",
    "    Lasso(alpha = para_las[1]['lasso__alpha'], random_state=1234))\n",
    "\n",
    "#Numerical pipeline\n",
    "pipe_num_las_best = make_pipeline(\n",
    "    PolynomialFeatures(degree = para_las[2]['polynomialfeatures__degree'], include_bias=True),\n",
    "    StandardScaler(),\n",
    "    Lasso(alpha = para_las[2]['lasso__alpha'], random_state=1234))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "efe95052-1d06-4deb-9ad2-0ce739e7ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit to training data\n",
    "# Fit title words\n",
    "pipe_tit_las_best.fit(X_dev_tit, y_dev)\n",
    "\n",
    "# Fit description words\n",
    "pipe_des_las_best.fit(X_dev_des, y_dev)\n",
    "\n",
    "# Fit numerical values\n",
    "pipe_num_las_best.fit(X_dev_num, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a71a73a-b058-4728-bdf4-6761ba919d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on test data\n",
    "accu_las_test = []\n",
    "mse_las_test = []\n",
    "\n",
    "# Words: \n",
    "y_hat_tit_test_las = pipe_tit_las_best.predict(X_test_tit)\n",
    "MSE_tit_test_las = mse(y_hat_tit_test_las,y_test)\n",
    "accuracy_tit_test_las =  np.mean(y_test.round(1)==y_hat_tit_test_las.round(1)) \n",
    "\n",
    "y_hat_des_test_las = pipe_des_las_best.predict(X_test_des)\n",
    "MSE_des_test_las = mse(y_hat_des_test_las,y_test)\n",
    "accuracy_des_test_las =  np.mean(y_test.round(1)==y_hat_des_test_las.round(1)) \n",
    "\n",
    "#numerical variables\n",
    "\n",
    "y_hat_num_test_las = pipe_num_las_best.predict(X_test_num)\n",
    "MSE_num_test_las = mse(y_hat_num_test_las,y_test)\n",
    "accuracy_num_test_las =  np.mean(y_test.round(1)==y_hat_num_test_las.round(1)) \n",
    "\n",
    "#Append MSE and accuracy to list\n",
    "mse_las_test.append(MSE_tit_test_las)\n",
    "mse_las_test.append(MSE_des_test_las)\n",
    "mse_las_test.append(MSE_num_test_las)\n",
    "\n",
    "accu_las_test.append(accuracy_tit_test_las)\n",
    "accu_las_test.append(accuracy_des_test_las)\n",
    "accu_las_test.append(accuracy_num_test_las)\n",
    "\n",
    "print(accu_las_test, mse_las_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f67ba5-6f26-4c05-bec3-9ef4edf7d1fc",
   "metadata": {},
   "source": [
    "## Elastic net - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51a38f57-013a-4bfb-8bb1-2b5a04029dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title pipeline\n",
    "pipe_tit_elas_best = make_pipeline(TfidfVectorizer(),\n",
    "    ElasticNet(alpha = para_elas[0]['elasticnet__alpha'], \n",
    "               l1_ratio  = para_elas[0]['elasticnet__l1_ratio'], \n",
    "               random_state=1234)\n",
    "                                  )\n",
    "\n",
    "#Description pipeline\n",
    "pipe_des_elas_best = make_pipeline(TfidfVectorizer(),\n",
    "    ElasticNet(alpha = para_elas[1]['elasticnet__alpha'], \n",
    "               l1_ratio  = para_elas[1]['elasticnet__l1_ratio'], \n",
    "               random_state=1234)\n",
    "                                  )\n",
    "\n",
    "#Numerical pipeline\n",
    "pipe_num_elas_best = make_pipeline(\n",
    "    PolynomialFeatures(degree = para_elas[2]['polynomialfeatures__degree'], include_bias=True),\n",
    "    StandardScaler(),\n",
    "    ElasticNet(alpha = para_elas[2]['elasticnet__alpha'], \n",
    "               l1_ratio  = para_elas[2]['elasticnet__l1_ratio'], \n",
    "               random_state=1234)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a6d0aeaa-f4ad-4adf-8beb-e4a204545844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training data\n",
    "# Fit title words\n",
    "pipe_tit_elas_best.fit(X_dev_tit, y_dev)\n",
    "\n",
    "# Fit description words\n",
    "pipe_des_elas_best.fit(X_dev_des, y_dev)\n",
    "\n",
    "# Fit numerical values\n",
    "pipe_num_elas_best.fit(X_dev_num, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8222d1e7-173a-4338-88f9-a9dac8010c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test data\n",
    "accu_elas_test = []\n",
    "mse_elas_test = []\n",
    "\n",
    "# Words: \n",
    "y_hat_tit_test_elas = pipe_tit_elas_best.predict(X_test_tit)\n",
    "MSE_tit_test_elas = mse(y_hat_tit_test_elas,y_test)\n",
    "accuracy_tit_test_elas =  np.mean(y_test.round(1)==y_hat_tit_test_elas.round(1)) \n",
    "\n",
    "y_hat_des_test_elas = pipe_des_elas_best.predict(X_test_des)\n",
    "MSE_des_test_elas = mse(y_hat_des_test_elas,y_test)\n",
    "accuracy_des_test_elas =  np.mean(y_test.round(1)==y_hat_des_test_elas.round(1)) \n",
    "\n",
    "#numerical variables\n",
    "\n",
    "y_hat_num_test_elas = pipe_num_elas_best.predict(X_test_num)\n",
    "MSE_num_test_elas = mse(y_hat_num_test_elas,y_test)\n",
    "accuracy_num_test_elas =  np.mean(y_test.round(1)==y_hat_num_test_elas.round(1)) \n",
    "\n",
    "#Append MSE and accuracy to list\n",
    "mse_elas_test.append(MSE_tit_test_elas)\n",
    "mse_elas_test.append(MSE_des_test_elas)\n",
    "mse_elas_test.append(MSE_num_test_elas)\n",
    "\n",
    "accu_elas_test.append(accuracy_tit_test_elas)\n",
    "accu_elas_test.append(accuracy_des_test_elas)\n",
    "accu_elas_test.append(accuracy_num_test_elas)\n",
    "\n",
    "print(accu_elas_test, mse_elas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc060384-a25f-404c-816f-959c5fc03468",
   "metadata": {},
   "source": [
    "## OLS - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "129c819a-2a66-4df1-bad8-ffb832a07aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title pipeline\n",
    "pipe_tit_ols_best = make_pipeline(TfidfVectorizer(),\n",
    "                                LinearRegression())\n",
    "\n",
    "#Description pipeline\n",
    "pipe_des_ols_best = make_pipeline(TfidfVectorizer(),\n",
    "                                LinearRegression())\n",
    "\n",
    "#Numerical pipeline\n",
    "pipe_num_ols_best = make_pipeline(\n",
    "                            PolynomialFeatures(degree =para_ols['polynomialfeatures__degree'], include_bias=True),\n",
    "                            StandardScaler(),\n",
    "                            LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f787ccbe-62eb-4204-a460-b392fd3c7c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training data\n",
    "# Fit title words\n",
    "pipe_tit_ols_best.fit(X_dev_tit, y_dev)\n",
    "\n",
    "# Fit description words\n",
    "pipe_des_ols_best.fit(X_dev_des, y_dev)\n",
    "\n",
    "# Fit numerical values\n",
    "pipe_num_ols_best.fit(X_dev_num, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1bba4f1f-b57d-4bf6-a091-453d04f3956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test data\n",
    "accu_ols_test = []\n",
    "mse_ols_test = []\n",
    "\n",
    "# Words: \n",
    "y_hat_tit_test_ols = pipe_tit_ols_best.predict(X_test_tit)\n",
    "MSE_tit_test_ols = mse(y_hat_tit_test_ols,y_test)\n",
    "accuracy_tit_test_ols =  np.mean(y_test.round(1)==y_hat_tit_test_ols.round(1)) \n",
    "\n",
    "y_hat_des_test_ols = pipe_des_ols_best.predict(X_test_des)\n",
    "MSE_des_test_ols = mse(y_hat_des_test_ols,y_test)\n",
    "accuracy_des_test_ols =  np.mean(y_test.round(1)==y_hat_des_test_ols.round(1)) \n",
    "\n",
    "#numerical variables\n",
    "\n",
    "y_hat_num_test_ols = pipe_num_ols_best.predict(X_test_num)\n",
    "MSE_num_test_ols = mse(y_hat_num_test_ols,y_test)\n",
    "accuracy_num_test_ols =  np.mean(y_test.round(1)==y_hat_num_test_ols.round(1)) \n",
    "\n",
    "#Append MSE and accuracy to list\n",
    "mse_ols_test.append(MSE_tit_test_ols)\n",
    "mse_ols_test.append(MSE_des_test_ols)\n",
    "mse_ols_test.append(MSE_num_test_ols)\n",
    "\n",
    "accu_ols_test.append(accuracy_tit_test_ols)\n",
    "accu_ols_test.append(accuracy_des_test_ols)\n",
    "accu_ols_test.append(accuracy_num_test_ols)\n",
    "\n",
    "print(accu_ols_test, mse_ols_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb67c1-9d47-4ea5-a337-992c384ce959",
   "metadata": {},
   "source": [
    "## Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ca53e11f-75ab-49a1-bec5-ff2b9361730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists\n",
    "x_data = [X_dev_num, X_dev_tit, X_dev_des]\n",
    "Title = ['Numerical variables', 'Title', 'Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d2509173-5cf7-4f81-9154-65d1d9fc922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "best_pipeline_lasso = [pipe_num_las_best, pipe_tit_las_best, pipe_des_las_best]\n",
    "\n",
    "f_lasso, ax1 = plt.subplots(1, 3, figsize=(20,3))\n",
    "\n",
    "for i, model1 in enumerate(best_pipeline_lasso):\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        learning_curve(estimator=model1,\n",
    "                   X=x_data[i],\n",
    "                   y=y_dev,\n",
    "                   train_sizes=np.arange(0.05, 1.05, .05),\n",
    "                   scoring='neg_mean_squared_error',                 \n",
    "                   cv=3)\n",
    "    \n",
    "    ax1[i].fill_between(train_sizes, -test_scores.min(1), -test_scores.max(1), alpha=0.25, label ='Validation', color='blue')\n",
    "    ax1[i].fill_between(train_sizes, -train_scores.min(1), -train_scores.max(1),  alpha=0.25, label='Train', color='red')\n",
    "\n",
    "    ax1[i].set_title(f'Lasso - {Title[i]}')\n",
    "\n",
    "ax1[0].set_ylabel('Mean squared error')\n",
    "\n",
    "plt.savefig(fp_data /'lasso.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d68c2d50-6397-4203-b47c-921ea3848344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic net\n",
    "best_pipeline_elastic = [pipe_num_elas_best, pipe_tit_elas_best, pipe_des_elas_best]\n",
    "\n",
    "f_elas, ax2 = plt.subplots(1, 3, figsize=(20,3))\n",
    "\n",
    "for j, model2 in enumerate(best_pipeline_elastic):\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        learning_curve(estimator=model2,\n",
    "                   X=x_data[j],\n",
    "                   y=y_dev,\n",
    "                   train_sizes=np.arange(0.05, 1.05, .05),\n",
    "                   scoring='neg_mean_squared_error',                 \n",
    "                   cv=3)\n",
    "    \n",
    "    ax2[j].fill_between(train_sizes, -test_scores.min(1), -test_scores.max(1), alpha=0.25, label ='Validation', color='blue')\n",
    "    ax2[j].fill_between(train_sizes, -train_scores.min(1), -train_scores.max(1),  alpha=0.25, label='Train', color='red')\n",
    "\n",
    "    ax2[j].set_title(f'Elastic - {Title[j]}')\n",
    "\n",
    "ax2[0].set_ylabel('Mean squared error')\n",
    "ax2[0].set_ylim(-0.05,0.6)\n",
    "\n",
    "plt.savefig(fp_data /'elastic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ff91ffa9-7dd1-40d4-8ab8-d29474e934f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLS\n",
    "best_pipeline_ols = [pipe_num_ols_best, pipe_tit_ols_best, pipe_des_ols_best]\n",
    "\n",
    "f_ols, ax3 = plt.subplots(1, 3, figsize=(20,3))\n",
    "\n",
    "for k, model3 in enumerate(best_pipeline_ols):\n",
    "    train_sizes, train_scores, test_scores = \\\n",
    "        learning_curve(estimator=model3,\n",
    "                   X=x_data[k],\n",
    "                   y=y_dev,\n",
    "                   train_sizes=np.arange(0.05, 1.05, .05),\n",
    "                   scoring='neg_mean_squared_error',                 \n",
    "                   cv=3)\n",
    "    \n",
    "    ax3[k].fill_between(train_sizes, -test_scores.min(1), -test_scores.max(1), alpha=0.25, label ='Validation', color='blue')\n",
    "    ax3[k].fill_between(train_sizes, -train_scores.min(1), -train_scores.max(1),  alpha=0.25, label='Train', color='red')\n",
    "\n",
    "    ax3[k].set_title(f'OLS - {Title[k]}')\n",
    "\n",
    "\n",
    "ax3[0].set_ylabel('Mean squared error')\n",
    "ax3[1].set_ylim(-0.05,1.25)\n",
    "ax3[0].legend();\n",
    "ax3[0].set_ylim(-0.05,0.6)\n",
    "\n",
    "plt.savefig(fp_data /'ols.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6f83c94c-9906-4234-86ed-a003a327e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "fig_combined = plt.figure(figsize=(20, 10))\n",
    "  \n",
    "# setting values to rows and column variables\n",
    "rows = 3\n",
    "columns = 1\n",
    "  \n",
    "# reading images\n",
    "lasso = fp_data /'lasso.png'\n",
    "image_lasso = Image.open(lasso)\n",
    "\n",
    "elastic = fp_data /'elastic.png'\n",
    "image_elas = Image.open(elastic)\n",
    "\n",
    "ols = fp_data /'ols.png'\n",
    "image_ols = Image.open(ols)\n",
    "\n",
    "# Adds a subplot at the 1st position (ols)\n",
    "fig_combined.add_subplot(rows, columns, 1)\n",
    "  \n",
    "# showing image\n",
    "plt.imshow(image_ols)\n",
    "plt.axis('off')\n",
    "\n",
    "# Adds a subplot at the 2nd position (lasso)\n",
    "fig_combined.add_subplot(rows, columns, 2)\n",
    "  \n",
    "# showing image\n",
    "plt.imshow(image_lasso)\n",
    "plt.axis('off')\n",
    "\n",
    "# Adds a subplot at the 3rd position (elas)\n",
    "fig_combined.add_subplot(rows, columns, 3)\n",
    "  \n",
    "# showing image\n",
    "plt.imshow(image_elas)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig(fp_data /'Learning curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aaaa7d-0eb6-4f6a-8e28-88f7902b022b",
   "metadata": {},
   "source": [
    "## Validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db74ccce-e4eb-490e-af20-9aa9668ab14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists\n",
    "x_data = [X_dev_num, X_dev_tit, X_dev_des]\n",
    "Title = ['Numerical variables (1)', 'Title (2)', 'Description (3)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "85d68ee7-514b-4b58-a05c-6c1cc4ed7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "best_pipeline_lasso = [pipe_num_las_best, pipe_tit_las_best, pipe_des_las_best]\n",
    "\n",
    "results_lasso_df = pd.DataFrame()\n",
    "\n",
    "for i, model in enumerate(best_pipeline_lasso):\n",
    "\n",
    "    train_scores, test_scores = \\\n",
    "        validation_curve(estimator=model,\n",
    "                     X=x_data[i],\n",
    "                     y=y_dev,\n",
    "                     param_name='lasso__alpha', #built-in name of hyperparameter\n",
    "                     param_range=lambdas, #values to consider\n",
    "                     scoring='neg_mean_squared_error',                 \n",
    "                     cv=3)\n",
    "\n",
    "    # OBTAIN MSE FOR DIFFERENT LAMBDAS AND PRINT BEST\n",
    "    mse_score = pd.DataFrame({'lambda':lambdas,\n",
    "                              'Train':-train_scores.mean(axis=1),\n",
    "                              'Validation':-test_scores.mean(axis=1)})\\\n",
    "                              .set_index('lambda')\n",
    "    \n",
    "    results_lasso_df = pd.concat([results_lasso_df, mse_score], axis=1)\n",
    "    print(mse_score['Validation'].nsmallest(1))\n",
    "    lambda_smallest = mse_score['Validation'].nsmallest(1) \n",
    "    lam = lambda_smallest.index[0]  #finds the lamda that gives the smallet mse\n",
    "    \n",
    "    mse_score.plot(logx=True, figsize=(8,6));  #creates plot for training and validation data\n",
    "    plt.axvline(x=lam, color='black', linestyle='--')  #creates the line that shows the optimal lambda \n",
    "    \n",
    "    if i == len(best_pipeline_lasso) - 3:\n",
    "        plt.ylabel(\"Mean squared error\") #Add ylabel to the first figure\n",
    "    \n",
    "    if i == len(best_pipeline_lasso) - 1: \n",
    "        plt.legend(fontsize=15) # Add legend for the last figure\n",
    "    else:\n",
    "        plt.gca().get_legend().remove() # Remove legend for previous figures\n",
    "    \n",
    "    plt.savefig(fp_data /f'{Title[i]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eef621e7-2373-4f8c-8321-9af5c85ae438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial features - lasso (num)\n",
    "train_scores, test_scores = \\\n",
    "    validation_curve(estimator=pipe_num_las_best,\n",
    "                     X=X_dev_num,\n",
    "                     y=y_dev,\n",
    "                     param_name='polynomialfeatures__degree', #built-in name of hyperparameter\n",
    "                     param_range=degrees, #values to consider\n",
    "                     scoring='neg_mean_squared_error',                 \n",
    "                     cv=3)\n",
    "\n",
    "# OBTAIN MSE FOR DIFFERENT LAMBDAS AND PRINT BEST\n",
    "mse_score_num_las = pd.DataFrame({'Train':-train_scores.mean(axis=1),\n",
    "                          'Validation':-test_scores.mean(axis=1),\n",
    "                          'poly':degrees})\\\n",
    "              .set_index('poly')   \n",
    "print(mse_score_num_las.Validation.nsmallest(1))\n",
    "\n",
    "mse_score_num_las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cbeeed8d-b5fa-45cd-b905-9c15e62bfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial features - Elas (num)\n",
    "train_scores, test_scores = \\\n",
    "    validation_curve(estimator=pipe_num_elas_best,\n",
    "                     X=X_dev_num,\n",
    "                     y=y_dev,\n",
    "                     param_name='polynomialfeatures__degree', #built-in name of hyperparameter\n",
    "                     param_range=degrees, #values to consider\n",
    "                     scoring='neg_mean_squared_error',                 \n",
    "                     cv=3)\n",
    "\n",
    "# OBTAIN MSE FOR DIFFERENT LAMBDAS AND PRINT BEST\n",
    "mse_score_num_elas = pd.DataFrame({'Train':-train_scores.mean(axis=1),\n",
    "                          'Validation':-test_scores.mean(axis=1),\n",
    "                          'poly':degrees})\\\n",
    "              .set_index('poly')   \n",
    "print(mse_score_num_elas.Validation.nsmallest(1))\n",
    "\n",
    "mse_score_num_elas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "db8fb833-f0d1-442c-a216-00abedae3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial features - OLS (num)\n",
    "train_scores, test_scores = \\\n",
    "    validation_curve(estimator=pipe_num_ols_best,\n",
    "                     X=X_dev_num,\n",
    "                     y=y_dev,\n",
    "                     param_name='polynomialfeatures__degree', #built-in name of hyperparameter\n",
    "                     param_range=degrees, #values to consider\n",
    "                     scoring='neg_mean_squared_error',                 \n",
    "                     cv=3)\n",
    "\n",
    "# OBTAIN MSE FOR DIFFERENT LAMBDAS AND PRINT BEST\n",
    "mse_score_num_ols = pd.DataFrame({'Train':-train_scores.mean(axis=1),\n",
    "                          'Validation':-test_scores.mean(axis=1),\n",
    "                          'poly':degrees})\\\n",
    "              .set_index('poly')   \n",
    "print(mse_score_num_ols.Validation.nsmallest(1))\n",
    "\n",
    "mse_score_num_ols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
